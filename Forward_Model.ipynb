{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b5ff59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('fpl_fwd_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00ee4ef3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['season', 'gameweek', 'name', 'position', 'team', 'xP', 'assists',\n",
       "       'bonus', 'bps', 'clean_sheets', 'creativity', 'element', 'fixture',\n",
       "       'goals_conceded', 'goals_scored', 'ict_index', 'influence',\n",
       "       'kickoff_time', 'minutes', 'opponent_team', 'own_goals',\n",
       "       'penalties_missed', 'penalties_saved', 'red_cards', 'round', 'saves',\n",
       "       'selected', 'team_a_score', 'team_h_score', 'threat', 'total_points',\n",
       "       'transfers_balance', 'transfers_in', 'transfers_out', 'value',\n",
       "       'was_home', 'yellow_cards', 'expected_assists',\n",
       "       'expected_goal_involvements', 'expected_goals',\n",
       "       'expected_goals_conceded', 'starts', 'future_points'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6365bad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9705, 43)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8eacc50a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… FWD Feature Engineering Complete! New shape: (8924, 56)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load your data\n",
    "fwd_df = pd.read_csv(\"fpl_fwd_data.csv\")\n",
    "\n",
    "# Sort by player and gameweek\n",
    "fwd_df = fwd_df.sort_values(by=['element', 'gameweek']).reset_index(drop=True)\n",
    "\n",
    "# ðŸ”¹ Rolling averages (last 3 GWs)\n",
    "rolling_cols = ['goals_scored', 'assists', 'minutes', 'bonus', 'total_points']\n",
    "for col in rolling_cols:\n",
    "    fwd_df[f'{col}_last_3'] = fwd_df.groupby('element')[col].transform(lambda x: x.shift(1).rolling(window=3).mean())\n",
    "\n",
    "# ðŸ”¹ Per 90 stats\n",
    "fwd_df['goals_per_90'] = (fwd_df['goals_scored'] / (fwd_df['minutes'] + 1e-5)) * 90\n",
    "fwd_df['assists_per_90'] = (fwd_df['assists'] / (fwd_df['minutes'] + 1e-5)) * 90\n",
    "fwd_df['xg_per_90'] = (fwd_df['expected_goals'] / (fwd_df['minutes'] + 1e-5)) * 90\n",
    "fwd_df['xa_per_90'] = (fwd_df['expected_assists'] / (fwd_df['minutes'] + 1e-5)) * 90\n",
    "\n",
    "# ðŸ”¹ Involvements\n",
    "fwd_df['involvements_per_90'] = ((fwd_df['goals_scored'] + fwd_df['assists']) / (fwd_df['minutes'] + 1e-5)) * 90\n",
    "fwd_df['expected_involvements'] = fwd_df['expected_goal_involvements']\n",
    "\n",
    "# ðŸ”¹ Goal efficiency (actual vs expected)\n",
    "fwd_df['goal_efficiency'] = fwd_df['goals_scored'] - fwd_df['expected_goals']\n",
    "\n",
    "# ðŸ”¹ Form features\n",
    "fwd_df['attacking_threat'] = fwd_df['threat'] + fwd_df['creativity'] + fwd_df['influence']\n",
    "\n",
    "# ðŸ”¹ Clean up: drop rows with NaNs from rolling\n",
    "fwd_df = fwd_df.dropna()\n",
    "\n",
    "# Save engineered version\n",
    "fwd_df.to_csv(\"fpl_fwd_data.csv\", index=False)\n",
    "\n",
    "print(\"âœ… FWD Feature Engineering Complete! New shape:\", fwd_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37f21017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "future_points                 1.000000\n",
       "minutes                       0.519317\n",
       "xP                            0.440234\n",
       "starts                        0.434625\n",
       "minutes_last_3                0.430538\n",
       "attacking_threat              0.424709\n",
       "ict_index                     0.423546\n",
       "total_points                  0.400387\n",
       "threat                        0.398073\n",
       "total_points_last_3           0.392931\n",
       "expected_goals_conceded       0.366349\n",
       "influence                     0.355705\n",
       "bps                           0.354085\n",
       "creativity                    0.349143\n",
       "selected                      0.341706\n",
       "expected_goal_involvements    0.339566\n",
       "expected_involvements         0.339566\n",
       "value                         0.325884\n",
       "goals_conceded                0.319210\n",
       "expected_goals                0.318286\n",
       "goals_scored_last_3           0.301094\n",
       "goals_scored                  0.286042\n",
       "transfers_in                  0.284600\n",
       "bonus_last_3                  0.274750\n",
       "bonus                         0.248919\n",
       "clean_sheets                  0.247001\n",
       "expected_assists              0.230831\n",
       "transfers_out                 0.219870\n",
       "assists_last_3                0.205458\n",
       "yellow_cards                  0.160808\n",
       "assists                       0.153050\n",
       "xg_per_90                     0.124434\n",
       "goals_per_90                  0.111255\n",
       "involvements_per_90           0.100043\n",
       "xa_per_90                     0.093301\n",
       "transfers_balance             0.089518\n",
       "goal_efficiency               0.076470\n",
       "penalties_missed              0.033739\n",
       "assists_per_90                0.031969\n",
       "opponent_team                 0.006541\n",
       "team_h_score                  0.005421\n",
       "own_goals                    -0.004386\n",
       "red_cards                    -0.009935\n",
       "team_a_score                 -0.013118\n",
       "was_home                     -0.021557\n",
       "fixture                      -0.044882\n",
       "round                        -0.045186\n",
       "gameweek                     -0.045186\n",
       "element                      -0.145969\n",
       "penalties_saved                    NaN\n",
       "saves                              NaN\n",
       "Name: future_points, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fwd_df.corr(numeric_only=True)['future_points'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "689c2ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fwd_df.drop(['team_h_score','team_a_score','was_home','own_goals','red_cards','fixture','round','element','saves','penalties_saved'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9cde0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fwd_df.to_csv('fpl_fwd_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f759b383",
   "metadata": {},
   "source": [
    "# ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1064c0ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001510 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4867\n",
      "[LightGBM] [Info] Number of data points in the train set: 6688, number of used features: 39\n",
      "[LightGBM] [Info] Start training from score 1.334181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shaunak\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=1.46442e-18): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\shaunak\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=1.44524e-18): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\shaunak\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=1.46151e-18): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\shaunak\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=1.50301e-18): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\shaunak\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=9.23044e-19): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\shaunak\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=1.44871e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\shaunak\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=1.42998e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\shaunak\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=1.4462e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\shaunak\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=1.41074e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\shaunak\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=8.75094e-18): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\shaunak\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=8.57543e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\shaunak\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=1.06328e-16): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\shaunak\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.719e+03, tolerance: 3.614e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\shaunak\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.955e+03, tolerance: 3.835e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\shaunak\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.414e+03, tolerance: 3.745e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\shaunak\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.112e+03, tolerance: 3.929e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\shaunak\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.187e+01, tolerance: 3.835e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\shaunak\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.015e+04, tolerance: 3.614e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\shaunak\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.103e+04, tolerance: 3.835e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\shaunak\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.154e+04, tolerance: 3.745e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\shaunak\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.243e+04, tolerance: 3.792e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\shaunak\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.292e+04, tolerance: 3.929e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\shaunak\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.942e+03, tolerance: 3.614e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\shaunak\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.812e+01, tolerance: 3.835e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\shaunak\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.827e+03, tolerance: 3.745e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\shaunak\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.084e+03, tolerance: 3.792e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\shaunak\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.106e+02, tolerance: 3.929e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Model Performance Comparison:\n",
      "            Model    MAE    MSE     RÂ²\n",
      "     HistGradient 1.0326 4.6998 0.2958\n",
      "Linear Regression 1.0431 4.6347 0.3055\n",
      "            Ridge 1.0433 4.6320 0.3059\n",
      "         LightGBM 1.0468 4.9136 0.2637\n",
      "          XGBoost 1.0684 4.9407 0.2597\n",
      "            Lasso 1.0925 4.6732 0.2997\n",
      "         CatBoost 1.0982 5.0646 0.2411\n",
      "       ElasticNet 1.1182 4.6785 0.2990\n",
      "    Random Forest 1.1421 4.8684 0.2705\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "df=pd.read_csv('fpl_fwd_data.csv')\n",
    "\n",
    "# ðŸ”¹ Drop non-model-useful columns\n",
    "df = df.drop(columns=['season', 'name', 'position', 'team', 'kickoff_time'],axis=1)\n",
    "\n",
    "# ðŸ”¹ Drop NaNs due to rolling features\n",
    "df = df.dropna()\n",
    "\n",
    "# ðŸ”¹ Sort by time (so future rows don't leak into training)\n",
    "df = df.sort_values(by=['gameweek']).reset_index(drop=True)\n",
    "\n",
    "# âœ… Time-based split: train on GWs 1â€“30, test on GWs 31â€“38\n",
    "train_df = df[df['gameweek'] <= 30]\n",
    "test_df  = df[df['gameweek'] > 30]\n",
    "\n",
    "# ðŸ”¹ Split into features and target\n",
    "X_train = train_df.drop(columns=['future_points'])\n",
    "y_train = train_df['future_points']\n",
    "\n",
    "X_test = test_df.drop(columns=['future_points'])\n",
    "y_test = test_df['future_points']\n",
    "\n",
    "\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Random Forest\": RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    \"XGBoost\": XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42),\n",
    "    \"LightGBM\": LGBMRegressor(n_estimators=100, learning_rate=0.1, random_state=42),\n",
    "    \"CatBoost\": CatBoostRegressor(verbose=0, random_state=42),\n",
    "    \"HistGradient\":HistGradientBoostingRegressor(min_samples_leaf= 50, max_leaf_nodes= 15, max_iter= 150, max_depth= 3, learning_rate= 0.1, l2_regularization= 0.1),\n",
    "    \"Ridge\": GridSearchCV(Ridge(), {'alpha': [0.01, 0.1, 1.0, 10]}, cv=5),\n",
    "    \"Lasso\": GridSearchCV(Lasso(max_iter=10000), {'alpha': [0.01, 0.1, 1.0, 10]}, cv=5),\n",
    "    \"ElasticNet\": GridSearchCV(ElasticNet(max_iter=10000), {'alpha': [0.01, 0.1, 1.0, 10]}, cv=5),\n",
    "}\n",
    "\n",
    "# ===============================\n",
    "# Train & Evaluate\n",
    "# ===============================\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "\n",
    "    mae = mean_absolute_error(y_test, preds)\n",
    "    mse = mean_squared_error(y_test, preds)\n",
    "    r2 = r2_score(y_test, preds)\n",
    "\n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"MAE\": round(mae, 4),\n",
    "        \"MSE\": round(mse, 4),\n",
    "        \"RÂ²\": round(r2, 4)\n",
    "    })\n",
    "\n",
    "# ===============================\n",
    "# Show Results\n",
    "# ===============================\n",
    "results_df = pd.DataFrame(results).sort_values(by=\"MAE\")\n",
    "print(\"ðŸ“Š Model Performance Comparison:\")\n",
    "print(results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb298312",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ridge regression model performs best at 0.306 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc19ab43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shaunak\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=1.46442e-18): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\shaunak\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=1.44524e-18): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\shaunak\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=1.46151e-18): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\shaunak\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=1.50301e-18): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\shaunak\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=9.23044e-19): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\shaunak\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=1.44871e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\shaunak\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=1.42998e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\shaunak\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=1.4462e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\shaunak\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=1.41074e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\shaunak\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=8.75094e-18): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\shaunak\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=8.57543e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Test MAE: 1.0433\n",
      "ðŸ“ˆ Test RÂ² Score: 0.3059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shaunak\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=1.06328e-16): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "df=pd.read_csv('fpl_fwd_data.csv')\n",
    "\n",
    "# ðŸ”¹ Drop non-model-useful columns\n",
    "df = df.drop(columns=['season', 'name', 'position', 'team', 'kickoff_time'],axis=1)\n",
    "\n",
    "# ðŸ”¹ Drop NaNs due to rolling features\n",
    "df = df.dropna()\n",
    "\n",
    "# ðŸ”¹ Sort by time (so future rows don't leak into training)\n",
    "df = df.sort_values(by=['gameweek']).reset_index(drop=True)\n",
    "\n",
    "# âœ… Time-based split: train on GWs 1â€“30, test on GWs 31â€“38\n",
    "train_df = df[df['gameweek'] <= 30]\n",
    "test_df  = df[df['gameweek'] > 30]\n",
    "\n",
    "# ðŸ”¹ Split into features and target\n",
    "X_train = train_df.drop(columns=['future_points'])\n",
    "y_train = train_df['future_points']\n",
    "\n",
    "X_test = test_df.drop(columns=['future_points'])\n",
    "y_test = test_df['future_points']\n",
    "\n",
    "model=GridSearchCV(Ridge(), {'alpha': [0.01, 0.1, 1.0, 10]}, cv=5)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "preds = model.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, preds)\n",
    "mse = mean_squared_error(y_test, preds)\n",
    "r2 = r2_score(y_test, preds)\n",
    "\n",
    "\n",
    "print(f\"\\nðŸ“Š Test MAE: {mae:.4f}\")\n",
    "print(f\"ðŸ“ˆ Test RÂ² Score: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0e33a7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fwd_model.pkl']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(model,'fwd_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4610541b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
