{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b871a779",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('fpl_mid_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "953b2ada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "season                        0\n",
       "gameweek                      0\n",
       "name                          0\n",
       "position                      0\n",
       "team                          0\n",
       "xP                            0\n",
       "assists                       0\n",
       "bonus                         0\n",
       "bps                           0\n",
       "clean_sheets                  0\n",
       "creativity                    0\n",
       "element                       0\n",
       "fixture                       0\n",
       "goals_conceded                0\n",
       "goals_scored                  0\n",
       "ict_index                     0\n",
       "influence                     0\n",
       "kickoff_time                  0\n",
       "minutes                       0\n",
       "opponent_team                 0\n",
       "own_goals                     0\n",
       "penalties_missed              0\n",
       "penalties_saved               0\n",
       "red_cards                     0\n",
       "round                         0\n",
       "saves                         0\n",
       "selected                      0\n",
       "team_a_score                  0\n",
       "team_h_score                  0\n",
       "threat                        0\n",
       "total_points                  0\n",
       "transfers_balance             0\n",
       "transfers_in                  0\n",
       "transfers_out                 0\n",
       "value                         0\n",
       "was_home                      0\n",
       "yellow_cards                  0\n",
       "expected_assists              0\n",
       "expected_goal_involvements    0\n",
       "expected_goals                0\n",
       "expected_goals_conceded       0\n",
       "starts                        0\n",
       "future_points                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ac5f332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35452, 43)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0973c151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Feature engineering for midfielders complete. New shape: (33414, 54)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load your midfielder data\n",
    "mid_df = pd.read_csv(\"fpl_mid_data.csv\")\n",
    "\n",
    "# Sort by player & gameweek to compute rolling stats\n",
    "mid_df = mid_df.sort_values(by=['element', 'gameweek']).reset_index(drop=True)\n",
    "\n",
    "# Rolling average of last 3 gameweeks\n",
    "rolling_features = ['total_points', 'minutes', 'goals_scored', 'assists', 'bonus']\n",
    "for col in rolling_features:\n",
    "    mid_df[f'{col}_last_3'] = mid_df.groupby('element')[col].transform(lambda x: x.shift(1).rolling(window=3).mean())\n",
    "\n",
    "# ðŸ”¹ Involvement per 90\n",
    "mid_df['goals_per_90'] = (mid_df['goals_scored'] / (mid_df['minutes'] + 1e-5)) * 90\n",
    "mid_df['assists_per_90'] = (mid_df['assists'] / (mid_df['minutes'] + 1e-5)) * 90\n",
    "mid_df['involvements_per_90'] = ((mid_df['goals_scored'] + mid_df['assists']) / (mid_df['minutes'] + 1e-5)) * 90\n",
    "\n",
    "# ðŸ”¹ Expected contribution\n",
    "mid_df['expected_contribution'] = mid_df['expected_goals'] + mid_df['expected_assists']\n",
    "\n",
    "# ðŸ”¹ Attacking intensity\n",
    "mid_df['attacking_threat'] = mid_df['threat'] + mid_df['creativity']\n",
    "\n",
    "# ðŸ”¹ Clean sheet bonus potential\n",
    "mid_df['clean_sheet_bonus'] = mid_df['clean_sheets'] * 1  # MID gets 1pt for CS\n",
    "\n",
    "# Drop rows with NaNs from rolling features\n",
    "mid_df = mid_df.dropna()\n",
    "\n",
    "# Save engineered version\n",
    "mid_df.to_csv(\"fpl_mid_data.csv\", index=False)\n",
    "\n",
    "print(\"âœ… Feature engineering for midfielders complete. New shape:\", mid_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a0d2876",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('fpl_mid_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e2f4f9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "future_points                 1.000000\n",
       "minutes                       0.504226\n",
       "xP                            0.468975\n",
       "ict_index                     0.454706\n",
       "attacking_threat              0.451669\n",
       "starts                        0.425444\n",
       "bps                           0.415879\n",
       "total_points                  0.405791\n",
       "creativity                    0.395623\n",
       "threat                        0.390117\n",
       "influence                     0.386685\n",
       "expected_contribution         0.368059\n",
       "expected_goal_involvements    0.365097\n",
       "value                         0.359462\n",
       "expected_goals_conceded       0.352064\n",
       "minutes_last_3                0.350374\n",
       "selected                      0.327996\n",
       "total_points_last_3           0.320647\n",
       "expected_assists              0.308990\n",
       "goals_conceded                0.302676\n",
       "expected_goals                0.299347\n",
       "transfers_in                  0.252877\n",
       "clean_sheet_bonus             0.238502\n",
       "clean_sheets                  0.238502\n",
       "goals_scored                  0.214034\n",
       "goals_scored_last_3           0.194658\n",
       "bonus                         0.193081\n",
       "assists                       0.191588\n",
       "bonus_last_3                  0.185804\n",
       "assists_last_3                0.169444\n",
       "transfers_out                 0.169386\n",
       "yellow_cards                  0.133575\n",
       "transfers_balance             0.088007\n",
       "involvements_per_90           0.085818\n",
       "goals_per_90                  0.072719\n",
       "assists_per_90                0.052965\n",
       "penalties_missed              0.033581\n",
       "own_goals                     0.015203\n",
       "team_h_score                  0.004370\n",
       "team_a_score                  0.001209\n",
       "opponent_team                -0.002508\n",
       "red_cards                    -0.011592\n",
       "was_home                     -0.013009\n",
       "fixture                      -0.023165\n",
       "round                        -0.023242\n",
       "gameweek                     -0.023242\n",
       "element                      -0.092571\n",
       "penalties_saved                    NaN\n",
       "saves                              NaN\n",
       "Name: future_points, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr(numeric_only=True)['future_points'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "143d39c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Columns dropped. New shape: (33414, 54)\n"
     ]
    }
   ],
   "source": [
    "cols_to_drop = [\n",
    "    'penalties_saved',\n",
    "    'saves',\n",
    "    'element',\n",
    "    'round',\n",
    "    'fixture',\n",
    "    'was_home',\n",
    "    'red_cards',\n",
    "    'opponent_team',\n",
    "    'team_a_score',\n",
    "    'team_h_score',\n",
    "    'own_goals',\n",
    "    'penalties_missed',\n",
    "    'yellow_cards',\n",
    "    'transfers_balance',         \n",
    "    'involvements_per_90' ,         \n",
    "    'goals_per_90',             \n",
    "    'assists_per_90'              \n",
    "]\n",
    "\n",
    "# Drop irrelevant columns\n",
    "df = df.drop(columns=cols_to_drop)\n",
    "\n",
    "# Save cleaned version (optional)\n",
    "df.to_csv(\"fpl_mid_data.csv\", index=False)\n",
    "\n",
    "print(\"âœ… Columns dropped. New shape:\", df.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0aa940",
   "metadata": {},
   "source": [
    "# Ml Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4101c093",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('fpl_mid_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5a766d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001769 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3813\n",
      "[LightGBM] [Info] Number of data points in the train set: 25357, number of used features: 31\n",
      "[LightGBM] [Info] Start training from score 1.250621\n",
      "ðŸ“Š Model Performance Comparison:\n",
      "            Model    MAE    MSE     RÂ²\n",
      "     HistGradient 0.9238 3.6862 0.3351\n",
      "         LightGBM 0.9457 3.8100 0.3127\n",
      "          XGBoost 0.9485 3.8217 0.3106\n",
      "         CatBoost 0.9555 3.8553 0.3046\n",
      "Linear Regression 0.9851 3.7507 0.3234\n",
      "    Random Forest 1.0674 4.0518 0.2691\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "\n",
    "# ðŸ”¹ Drop non-model-useful columns\n",
    "df = df.drop(columns=['season', 'name', 'position', 'team', 'kickoff_time'],axis=1)\n",
    "\n",
    "# ðŸ”¹ Drop NaNs due to rolling features\n",
    "df = df.dropna()\n",
    "\n",
    "# ðŸ”¹ Sort by time (so future rows don't leak into training)\n",
    "df = df.sort_values(by=['gameweek']).reset_index(drop=True)\n",
    "\n",
    "# âœ… Time-based split: train on GWs 1â€“30, test on GWs 31â€“38\n",
    "train_df = df[df['gameweek'] <= 30]\n",
    "test_df  = df[df['gameweek'] > 30]\n",
    "\n",
    "# ðŸ”¹ Split into features and target\n",
    "X_train = train_df.drop(columns=['future_points'])\n",
    "y_train = train_df['future_points']\n",
    "\n",
    "X_test = test_df.drop(columns=['future_points'])\n",
    "y_test = test_df['future_points']\n",
    "\n",
    "\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Random Forest\": RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    \"XGBoost\": XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42),\n",
    "    \"LightGBM\": LGBMRegressor(n_estimators=100, learning_rate=0.1, random_state=42),\n",
    "    \"CatBoost\": CatBoostRegressor(verbose=0, random_state=42),\n",
    "    \"HistGradient\":HistGradientBoostingRegressor(min_samples_leaf= 50, max_leaf_nodes= 15, max_iter= 150, max_depth= 3, learning_rate= 0.1, l2_regularization= 0.1)\n",
    "}\n",
    "\n",
    "# ===============================\n",
    "# Train & Evaluate\n",
    "# ===============================\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "\n",
    "    mae = mean_absolute_error(y_test, preds)\n",
    "    mse = mean_squared_error(y_test, preds)\n",
    "    r2 = r2_score(y_test, preds)\n",
    "\n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"MAE\": round(mae, 4),\n",
    "        \"MSE\": round(mse, 4),\n",
    "        \"RÂ²\": round(r2, 4)\n",
    "    })\n",
    "\n",
    "# ===============================\n",
    "# Show Results\n",
    "# ===============================\n",
    "results_df = pd.DataFrame(results).sort_values(by=\"MAE\")\n",
    "print(\"ðŸ“Š Model Performance Comparison:\")\n",
    "print(results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "596134c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shaunak\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=1.1162e-18): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\shaunak\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=1.10937e-18): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\shaunak\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=1.18796e-18): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\shaunak\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=1.23532e-18): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\shaunak\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=9.83228e-19): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\shaunak\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=1.11477e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\shaunak\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=1.10796e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\shaunak\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=1.18645e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\shaunak\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=1.23374e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\shaunak\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=9.3311e-18): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\shaunak\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=1.10145e-16): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\shaunak\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=1.09489e-16): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\shaunak\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=9.245e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Model Performance Comparison:\n",
      "           Model    MAE    MSE     RÂ²\n",
      "LinearRegression 0.9851 3.7507 0.3234\n",
      "           Ridge 0.9855 3.7494 0.3237\n",
      "      ElasticNet 0.9938 3.7588 0.3220\n",
      "           Lasso 0.9941 3.7640 0.3210\n",
      "    RandomForest 1.0674 4.0518 0.2691\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "models={\n",
    "    \"LinearRegression\": LinearRegression(),\n",
    "    \"Ridge\": GridSearchCV(Ridge(), {'alpha': [0.01, 0.1, 1.0, 10]}, cv=5),\n",
    "    \"Lasso\": GridSearchCV(Lasso(max_iter=10000), {'alpha': [0.01, 0.1, 1.0, 10]}, cv=5),\n",
    "    \"ElasticNet\": GridSearchCV(ElasticNet(max_iter=10000), {'alpha': [0.01, 0.1, 1.0, 10]}, cv=5),\n",
    "    \"RandomForest\": RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    }\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "\n",
    "    mae = mean_absolute_error(y_test, preds)\n",
    "    mse = mean_squared_error(y_test, preds)\n",
    "    r2 = r2_score(y_test, preds)\n",
    "\n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"MAE\": round(mae, 4),\n",
    "        \"MSE\": round(mse, 4),\n",
    "        \"RÂ²\": round(r2, 4)\n",
    "    })\n",
    "\n",
    "# ===============================\n",
    "# Show Results\n",
    "# ===============================\n",
    "results_df = pd.DataFrame(results).sort_values(by=\"MAE\")\n",
    "print(\"ðŸ“Š Model Performance Comparison:\")\n",
    "print(results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17ee921a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "âœ… Best Params: {'min_samples_leaf': 50, 'max_leaf_nodes': 15, 'max_iter': 100, 'max_depth': None, 'learning_rate': 0.2, 'l2_regularization': 1.0}\n",
      "\n",
      "ðŸ“Š Test MAE: 0.9232\n",
      "ðŸ“ˆ Test RÂ² Score: 0.3249\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Define model\n",
    "model = HistGradientBoostingRegressor(random_state=42)\n",
    "\n",
    "# Hyperparameter grid\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'max_iter': [100, 200, 300],\n",
    "    'max_leaf_nodes': [15, 31, 63],\n",
    "    'max_depth': [3, 5, 7, None],\n",
    "    'min_samples_leaf': [10, 20, 30, 50],\n",
    "    'l2_regularization': [0.0, 0.1, 0.5, 1.0]\n",
    "}\n",
    "\n",
    "# Randomized search with 5-fold CV on training data\n",
    "search = RandomizedSearchCV(model, param_distributions=param_grid, n_iter=30,\n",
    "                            scoring='neg_mean_absolute_error', cv=5,\n",
    "                            random_state=42, n_jobs=-1, verbose=1)\n",
    "\n",
    "# Fit on training data only\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "# Best model\n",
    "best_model = search.best_estimator_\n",
    "print(\"âœ… Best Params:\", search.best_params_)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"\\nðŸ“Š Test MAE: {mae:.4f}\")\n",
    "print(f\"ðŸ“ˆ Test RÂ² Score: {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2149a0f",
   "metadata": {},
   "source": [
    "# Best model found to HistGradientBoosting with R2 score of 0.34\n",
    "min_samples_leaf= 50, max_leaf_nodes= 15, max_iter= 150, max_depth= 3, learning_rate= 0.1, l2_regularization= 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92a92e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Test MAE: 0.9216\n",
      "ðŸ“ˆ Test RÂ² Score: 0.3348\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "\n",
    "# ðŸ”¹ Drop non-model-useful columns\n",
    "df = df.drop(columns=['season', 'name', 'position', 'team', 'kickoff_time'],axis=1)\n",
    "\n",
    "# ðŸ”¹ Drop NaNs due to rolling features\n",
    "df = df.dropna()\n",
    "\n",
    "# ðŸ”¹ Sort by time (so future rows don't leak into training)\n",
    "df = df.sort_values(by=['gameweek']).reset_index(drop=True)\n",
    "\n",
    "# âœ… Time-based split: train on GWs 1â€“30, test on GWs 31â€“38\n",
    "train_df = df[df['gameweek'] <= 30]\n",
    "test_df  = df[df['gameweek'] > 30]\n",
    "\n",
    "# ðŸ”¹ Split into features and target\n",
    "X_train = train_df.drop(columns=['future_points'])\n",
    "y_train = train_df['future_points']\n",
    "\n",
    "X_test = test_df.drop(columns=['future_points'])\n",
    "y_test = test_df['future_points']\n",
    "\n",
    "model=HistGradientBoostingRegressor(min_samples_leaf= 50, max_leaf_nodes= 15, max_iter= 150, max_depth= 3, learning_rate= 0.1, l2_regularization= 0.1)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "preds = model.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, preds)\n",
    "mse = mean_squared_error(y_test, preds)\n",
    "r2 = r2_score(y_test, preds)\n",
    "\n",
    "print(f\"\\nðŸ“Š Test MAE: {mae:.4f}\")\n",
    "print(f\"ðŸ“ˆ Test RÂ² Score: {r2:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "693875c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mid_model.pkl']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(model,'mid_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f6c582",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
